@INPROCEEDINGS{SD-VBS,
  author={Venkata, Sravanthi Kota and Ahn, Ikkjin and Jeon, Donghwan and Gupta, Anshuman and Louie, Christopher and Garcia, Saturnino and Belongie, Serge and Taylor, Michael Bedford},
  booktitle={2009 IEEE International Symposium on Workload Characterization (IISWC)}, 
  title={SD-VBS: The San Diego Vision Benchmark Suite}, 
  year={2009},
  volume={},
  number={},
  pages={55-64},
  keywords={Application software;Computer vision;Parallel processing;MATLAB;Drives;Energy efficiency;Portable computers;Computer architecture;Computational modeling;Runtime},
  doi={10.1109/IISWC.2009.5306794}}

@inproceedings{RT-Bench,
	author = {Nicolella, Mattia and Roozkhosh, Shahin and Hoornaert, Denis and Bastoni, Andrea and Mancuso, Renato},
	title = {RT-Bench: An Extensible Benchmark Framework for the Analysis and Management of Real-Time Applications},
	year = {2022},
	isbn = {9781450396509},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3534879.3534888},
	doi = {10.1145/3534879.3534888},
	booktitle = {Proceedings of the 30th International Conference on Real-Time Networks and Systems},
	pages = {184–195},
	numpages = {12},
	keywords = {portable, framework, real-time, profiling, extensible, periodic, benchmark suite, open-source, interference},
	location = {Paris, France},
	series = {RTNS 2022}
}


@inproceedings{ShahinCaesar,
  title={CAESAR: Coherence-Aided Elective and Seamless
Alternative Routing via on-chip FPGA},
  author={Shahin Roozkhosh and Denis Hoornaert},
  year={2022}
}



@online{CoreSight,
  author = {ARM},
  title = {CoreSight Components Technical Reference Manual},
  year = 2004,
  url = {https://developer.arm.com/documentation/ddi0314/h/}
}

@online{ia64_swdev_vol3,
  author = {Intel Corp.},
  title = {{Intel 64 and IA-32 Architectures Software Developer’s Manual Volume 3 (3A, 3B, 3C \& 3D): System Programming Guide}},
  year = 2022,
  url = {https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html}
}

@online{TMC,
  author = {ARM},
  title = {{CoreSight} Trace Memory Controller Technical Reference Manual},
  year = 2010,
  url = {https://developer.arm.com/documentation/ddi0461/b/}
}

@online{aarch64_spec,
  author = {ARM},
  title = {Arm Architecture Reference Manual for A-profile architecture},
  year = 2013,
  url = {https://developer.arm.com/documentation/ddi0487/latest}
}

@online{etm,
  author = {ARM},
  title = {Embedded Trace Macrocell Architecture Specification ETMv4.0 to ETM4.6},
  year = 2012,
  url = {https://developer.arm.com/documentation/ihi0064/h/?lang=en}
}

@online{risc-v_spec,
  author = {RISC-V},
  title = {The RISC-V Instruction Set Manual},
  year = 2021,
  url = {https://riscv.org/technical/specifications/}
}

@online{soc400,
  author = {ARM},
  title = {{ARM CoreSight SoC-400 Technical Reference Manual}},
  year = 2015,
  url = {https://developer.arm.com/Processors/CoreSight\%20SoC-400}
}

@inproceedings{MDBCCP:13,
	author = "{Mancuso}, R. and {Dudko}, R. and {Betti}, E. and {Cesati}, M. and {Caccamo}, M. and {Pellizzoni}, R.",
	booktitle = "{2013 IEEE 19th Real-Time and Embedded Technology and Applications Symposium (RTAS)}",
	number = "",
	pages = "45–54",
	title = "{Real-time cache management framework for multi-core architectures}",
	volume = "",
	year = "2013"
}

@inproceedings{CalciuPberry,
author = {Calciu, Irina and Puddu, Ivan and Kolli, Aasheesh and Nowatzyk, Andreas and Gandhi, Jayneel and Mutlu, Onur and Subrahmanyam, Pratap},
title = {Project PBerry: FPGA Acceleration for Remote Memory},
year = {2019},
isbn = {9781450367271},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3317550.3321424},
doi = {10.1145/3317550.3321424},
abstract = {Recent research efforts propose remote memory systems that pool memory from multiple hosts. These systems rely on the virtual memory subsystem to track application memory accesses and transparently offer remote memory to applications. We outline several limitations of this approach, such as page fault overheads and dirty data amplification. Instead, we argue for a fundamentally different approach: leverage the local host's cache coherence traffic to track application memory accesses at cache line granularity. Our approach uses emerging cache-coherent FPGAs to expose cache coherence events to the operating system. This approach not only accelerates remote memory systems by reducing dirty data amplification and by eliminating page faults, but also enables other use cases, such as live virtual machine migration, unified virtual memory, security and code analysis. All of these use cases open up many promising research directions.},
booktitle = {Proceedings of the Workshop on Hot Topics in Operating Systems},
pages = {127–135},
numpages = {9},
keywords = {remote memory, FPGA, cache coherence},
location = {Bertinoro, Italy},
series = {HotOS '19}
}

@article{BrunellaHxdp,
author = {Brunella, Marco Spaziani and Belocchi, Giacomo and Bonola, Marco and Pontarelli, Salvatore and Siracusano, Giuseppe and Bianchi, Giuseppe and Cammarano, Aniello and Palumbo, Alessandro and Petrucci, Luca and Bifulco, Roberto},
title = {HXDP: Efficient Software Packet Processing on FPGA NICs},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {65},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/3543668},
doi = {10.1145/3543668},
abstract = {The network interface cards (NICs) of modern computers are changing to adapt to faster data rates and to help with the scaling issues of general-purpose CPU technologies. Among the ongoing innovations, the inclusion of programmable accelerators on the NIC's data path is particularly interesting, since it provides the opportunity to offload some of the CPU's network packet processing tasks to the accelerator. Given the strict latency constraints of packet processing tasks, accelerators are often implemented leveraging platforms such as Field-Programmable Gate Arrays (FPGAs). FPGAs can be re-programmed after deployment, to adapt to changing application requirements, and can achieve both high throughput and low latency when implementing packet processing tasks. However, they have limited resources that may need to be shared among diverse applications, and programming them is difficult and requires hardware design expertise.We present hXDP, a solution to run on FPGAs software packet processing tasks described with the eBPF technology and targeting the Linux's eXpress Data Path. hXDP uses only a fraction of the available FPGA resources, while matching the performance of high-end CPUs. The iterative execution model of eBPF is not a good fit for FPGA accelerators. Nonetheless, we show that many of the instructions of an eBPF program can be compressed, parallelized, or completely removed, when targeting a purpose-built FPGA design, thereby significantly improving performance.We implement hXDP on an FPGA NIC and evaluate it running real-world unmodified eBPF programs. Our implementation runs at 156.25MHz and uses about 15% of the FPGA resources. Despite these modest requirements, it can run dynamically loaded programs, achieves the packet processing throughput of a high-end CPU core, and provides a 10X lower packet forwarding latency.},
journal = {Commun. ACM},
month = {jul},
pages = {92–100},
numpages = {9}
}

@inproceedings{AguileraVmWare,
author = {Aguilera, Marcos K. and Amit, Nadav and Calciu, Irina and Deguillard, Xavier and Gandhi, Jayneel and Subrahmanyam, Pratap and Suresh, Lalith and Tati, Kiran and Venkatasubramanian, Rajesh and Wei, Michael},
title = {Remote Memory in the Age of Fast Networks},
year = {2017},
isbn = {9781450350280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127479.3131612},
doi = {10.1145/3127479.3131612},
abstract = {As the latency of the network approaches that of memory, it becomes increasingly attractive for applications to use remote memory---random-access memory at another computer that is accessed using the virtual memory subsystem. This is an old idea whose time has come, in the age of fast networks. To work effectively, remote memory must address many technical challenges. In this paper, we enumerate these challenges, discuss their feasibility, explain how some of them are addressed by recent work, and indicate other promising ways to tackle them. Some challenges remain as open problems, while others deserve more study. In this paper, we hope to provide a broad research agenda around this topic, by proposing more problems than solutions.},
booktitle = {Proceedings of the 2017 Symposium on Cloud Computing},
pages = {121–127},
numpages = {7},
location = {Santa Clara, California},
series = {SoCC '17}
}

@inproceedings{SidlerStrom,
author = {Sidler, David and Wang, Zeke and Chiosa, Monica and Kulkarni, Amit and Alonso, Gustavo},
title = {StRoM: Smart Remote Memory},
year = {2020},
isbn = {9781450368827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342195.3387519},
doi = {10.1145/3342195.3387519},
abstract = {Big data applications often incur large costs in I/O, data transfer and copying overhead, especially when operating in cloud environments. Since most such computations are distributed, data processing operations offloaded to the network card (NIC) could potentially reduce the data movement overhead by enabling near-data processing at several points of a distributed system. Following this idea, in this paper we present StRoM, a programmable, FPGA-based RoCE v2 NIC supporting the offloading of application level kernels. These kernels can be used to perform memory access operations directly from the NIC such as traversal of remote data structures as well as filtering or aggregation over RDMA data streams on both the sending or receiving sides. StRoM bypasses the CPU entirely and extends the semantics of RDMA to enable multi-step data access operations and in-network processing of RDMA streams. We demonstrate the versatility and potential of StRoM with four different kernels extending one-sided RDMA commands: 1) Traversal of remote data structures through pointer chasing, 2) Consistent retrieval of remote data blocks, 3) Data shuffling on the NIC by partitioning incoming data to different memory regions or CPU cores, and 4) Cardinality estimation on data streams.},
booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems},
articleno = {29},
numpages = {16},
location = {Heraklion, Greece},
series = {EuroSys '20}
}

@INPROCEEDINGS{RoozkhoshPLIM,

  author={Roozkhosh, Shahin and Mancuso, Renato},

  booktitle={2020 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS)}, 

  title={The Potential of Programmable Logic in the Middle: Cache Bleaching}, 

  year={2020},

  volume={},

  number={},

  pages={296-309},

  doi={10.1109/RTAS48715.2020.00006}}


@article{ScalesShasta,
author = {Scales, Daniel J. and Gharachorloo, Kourosh and Thekkath, Chandramohan A.},
title = {Shasta: A Low Overhead, Software-Only Approach for Supporting Fine-Grain Shared Memory},
year = {1996},
issue_date = {Sept. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {9},
issn = {0362-1340},
url = {https://doi.org/10.1145/248209.237179},
doi = {10.1145/248209.237179},
abstract = {This paper describes Shasta, a system that supports a shared address space in software on clusters of computers with physically distributed memory. A unique aspect of Shasta compared to most other software distributed shared memory systems is that shared data can be kept coherent at a fine granularity. In addition, the system allows the coherence granularity to vary across different shared data structures in a single application. Shasta implements the shared address space by transparently rewriting the application executable to intercept loads and stores. For each shared load or store, the inserted code checks to see if the data is available locally and communicates with other processors if necessary. The system uses numerous techniques to reduce the run-time overhead of these checks. Since Shasta is implemented entirely in software, it also provides tremendous flexibility in supporting different types of cache coherence protocols. We have implemented an efficient cache coherence protocol that incorporates a number of optimizations, including support for multiple communication granularities and use of relaxed memory models. This system is fully functional and runs on a cluster of Alpha workstations.The primary focus of this paper is to describe the techniques used in Shasta to reduce the checking overhead for supporting fine granularity sharing in software. These techniques include careful layout of the shared address space, scheduling the checking code for efficient execution on modern processors, using a simple method that checks loads using only the value loaded, reducing the extra cache misses caused by the checking code, and combining the checks for multiple loads and stores. To characterize the effect of these techniques, we present detailed performance results for the SPLASH-2 applications running on an Alpha processor. Without our optimizations, the checking overheads are excessively high, exceeding 100\% for several applications. However, our techniques are effective in reducing these overheads to a range of 5\% to 35\% for almost all of the applications. We also describe our coherence protocol and present some preliminary results on the parallel performance of several applications running on our workstation cluster. Our experience so far indicates that once the cost of checking memory accesses is reduced using our techniques, the Shasta approach is an attractive software solution for supporting a shared address space with fine-grain access to data.},
journal = {SIGPLAN Not.},
month = {sep},
pages = {174–185},
numpages = {12}
}
@inproceedings{SchoinasFineControlDistSharedMem,
author = {Schoinas, Ioannis and Falsafi, Babak and Lebeck, Alvin R. and Reinhardt, Steven K. and Larus, James R. and Wood, David A.},
title = {Fine-Grain Access Control for Distributed Shared Memory},
year = {1994},
isbn = {0897916603},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/195473.195575},
doi = {10.1145/195473.195575},
abstract = {This paper discusses implementations of fine-grain memory access control, which selectively restricts reads and writes to cache-block-sized memory regions. Fine-grain access control forms the basis of efficient cache-coherent shared memory. This paper focuses on low-cost implementations that require little or no additional hardware. These techniques permit efficient implementation of shared memory on a wide range of parallel systems, thereby providing shared-memory codes with a portability previously limited to message passing.This paper categorizes techniques based on where access control is enforced and where access conflicts are handled. We incorporated three techniques that require no additional hardware into Blizzard, a system that supports distributed shared memory on the CM-5. The first adds a software lookup before each shared-memory reference by modifying the program's executable. The second uses the memory's error correcting code (ECC) as cache-block valid bits. The third is a hybrid. The software technique ranged from slightly faster to two times slower than the ECC approach. Blizzard's performance is roughly comparable to a hardware shared-memory machine. These results argue that clusters of workstations or personal computers with networks comparable to the CM-5's will be able to support the same shared-memory interfaces as supercomputers.},
booktitle = {Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {297–306},
numpages = {10},
location = {San Jose, California, USA},
series = {ASPLOS VI}
}


@article{BrueningTDI,
author = {Bruening, Derek and Zhao, Qin and Amarasinghe, Saman},
title = {Transparent Dynamic Instrumentation},
year = {2012},
issue_date = {July 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/2365864.2151043},
doi = {10.1145/2365864.2151043},
abstract = {Process virtualization provides a virtual execution environment within which an unmodified application can be monitored and controlled while it executes. The provided layer of control can be used for purposes ranging from sandboxing to compatibility to profiling. The additional operations required for this layer are performed clandestinely alongside regular program execution. Software dynamic instrumentation is one method for implementing process virtualization which dynamically instruments an application such that the application's code and the inserted code are interleaved together. DynamoRIO is a process virtualization system implemented using software code cache techniques that allows users to build customized dynamic instrumentation tools. There are many challenges to building such a runtime system. One major obstacle is transparency. In order to support executing arbitrary applications, DynamoRIO must be fully transparent so that an application cannot distinguish between running inside the virtual environment and native execution. In addition, any desired extra operations for a particular tool must avoid interfering with the behavior of the application.Transparency has historically been provided on an ad-hoc basis, as a reaction to observed problems in target applications. This paper identifies a necessary set of transparency requirements for running mainstream Windows and Linux applications. We discuss possible solutions to each transparency issue, evaluate tradeoffs between different choices, and identify cases where maintaining transparency is not practically solvable. We believe this will provide a guideline for better design and implementation of transparent dynamic instrumentation, as well as other similar process virtualization systems using software code caches.},
journal = {SIGPLAN Not.},
month = {mar},
pages = {133–144},
numpages = {12},
keywords = {runtime system, dynamic instrumentation, transparency, process virtualization}
}


@INPROCEEDINGS{OliverIntelCCFPGA,

  author={Oliver, Neal and Sharma, Rahul R. and Chang, Stephen and Chitlur, Bhushan and Garcia, Elkin and Grecco, Joseph and Grier, Aaron and Ijih, Nelson and Liu, Yaping and Marolia, Pratik and Mitchel, Henry and Subhaschandra, Suchit and Sheiman, Arthur and Whisonant, Tim and Gupta, Prabhat},

  booktitle={2011 International Conference on Reconfigurable Computing and FPGAs}, 

  title={A Reconfigurable Computing System Based on a Cache-Coherent Fabric}, 

  year={2011},

  volume={},

  number={},

  pages={80-85},

  doi={10.1109/ReConFig.2011.4}}


@INPROCEEDINGS{ForencichCorundum,

  author={Forencich, Alex and Snoeren, Alex C. and Porter, George and Papen, George},

  booktitle={2020 IEEE 28th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)}, 

  title={Corundum: An Open-Source 100-Gbps Nic}, 

  year={2020},

  volume={},

  number={},

  pages={38-46},

  doi={10.1109/FCCM48280.2020.00015}}


@ARTICLE{MizutaniOPTWEB,

  author={Mizutani, Kenji and Yamaguchi, Hiroshi and Urino, Yutaka and Koibuchi, Michihiro},

  journal={IEEE Transactions on Computers}, 

  title={OPTWEB: A Lightweight Fully Connected Inter-FPGA Network for Efficient Collectives}, 

  abstract={Modern FPGA accelerators can be equipped with many high-bandwidth network I/Os, e.g., 64 x 50 Gbps, enabled by
onboard optics or co-packaged optics. Some dozens of tightly coupled FPGA accelerators form an emerging computing platform for
distributed data processing. However, a conventional indirect packet network using Ethernet’s Intellectual Properties imposes an
unacceptably large amount of the logic for handling such high-bandwidth interconnects on an FPGA. Besides the indirect network,
another approach builds a direct packet network. Existing direct inter-FPGA networks have a low-radix network topology, e.g., 2-D
torus. However, the low-radix network has the disadvantage of a large diameter and large average shortest path length that increases
the latency of collectives. To mitigate both problems, we propose a lightweight, fully connected inter-FPGA network called OPTWEB for
efficient collectives. Since all end-to-end separate communication paths are statically established using onboard optics, raw block data
can be transferred with simple link-level synchronization. Once each source FPGA assigns a communication stream to a path by its
internal switch logic between memory-mapped and stream interfaces for remote direct memory access (RDMA), a one-hop transfer is
provided. Since each FPGA performs input/output of the remote memory access between all FPGAs simultaneously, multiple RDMAs
efficiently form collectives. The OPTWEB network provides 0.71-msec start-up latency of collectives among multiple Intel Stratix 10 MX
FPGA cards with onboard optics. The OPTWEB network consumes 31.4 and 57.7 percent of adaptive logic modules for aggregate
400-Gbps and 800-Gbps interconnects on a custom Stratix 10 MX 2100 FPGA, respectively. The OPTWEB network reduces by 40
percent the cost compared to a conventional packet network},

  year={2021},

  volume={70},

  number={6},

  pages={849-862},

  doi={10.1109/TC.2021.3068715}}

@INPROCEEDINGS{XU-16-PCIENTB,
  author={Jian Xu and Jianquan Zhang and Jian Zhang},
  booktitle={2016 2nd IEEE International Conference on Computer and Communications (ICCC)}, 
  title={Design of embedded heterogeneous platform based on PCIE non-transparent bridge}, 
  year={2016},
  volume={},
  number={},
  pages={915-919},
  keywords={Bridges;Computers;Switches;Graphics processing units;Ports (Computers);PCIE;non-transparent bridge;Linux;embedded;heterogeneous platform},
  doi={10.1109/CompComm.2016.7924837}}


@INPROCEEDINGS{EI-Sayed,
  author={Saad, El- Sayed M. and Awadalla, Medhat H. A. and El-Deen, Kareem Ezz},
  booktitle={2009 National Radio Science Conference}, 
  title={FPGA-based software profiler for Hardware/Software co-design}, 
  year={2009},
  volume={},
  number={},
  pages={1-8},
  keywords={Hardware;Software performance;Embedded system;Embedded software;Software tools;Field programmable gate arrays;Application specific integrated circuits;Time to market;Microprocessors;Costs},
  doi={}}%kind of old


@article{Feng21,
author = {Feng, Lang and Huang, Jeff and Hu, Jiang and Reddy, Abhijith},
title = {FastCFI: Real-time Control-Flow Integrity Using FPGA without Code Instrumentation},
year = {2021},
issue_date = {September 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {5},
issn = {1084-4309},
url = {https://doi.org/10.1145/3458471},
doi = {10.1145/3458471},
abstract = {Control-Flow Integrity (CFI) is an effective defense technique against a variety of memory-based cyber attacks. CFI is usually enforced through software methods, which entail considerable performance overhead. Hardware-based CFI techniques can largely avoid performance overhead, but typically rely on code instrumentation, forming a non-trivial hurdle to the application of CFI. Taking advantage of the tradeoff between computing efficiency and flexibility of FPGA, we develop FastCFI, an FPGA-based CFI system that can perform fine-grained and stateful checking without code instrumentation. We also propose an automated Verilog generation technique that facilitates fast deployment of FastCFI, and a compression algorithm for reducing the hardware expense. Experiments on popular benchmarks confirm that FastCFI can detect fine-grained CFI violations over unmodified binaries. When using FastCFI on prevalent benchmarks, we demonstrate its capability to detect fine-grained CFI violations in unmodified binaries, while incurring an average of 0.36\% overhead and a maximum of 2.93\% overhead.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = jun,
articleno = {39},
numpages = {39},
keywords = {security, field-programmable gate array, Control-flow integrity}
}

@INPROCEEDINGS{hoppe21,
  author={Hoppe, Augusto and Becker, Jürgen and Kastensmidt, Fernanda Lima},
  booktitle={2021 IEEE 12th Latin America Symposium on Circuits and System (LASCAS)}, 
  title={High-speed Hardware Accelerator for Trace Decoding in Real-Time Program Monitoring}, 
  year={2021},
  volume={},
  number={},
  pages={1-4},
  keywords={Program processors;Multicore processing;Focusing;Real-time systems;Hardware;Decoding;Safety;Control Flow Monitoring;ARM Cortex-A9;CoreSight;Online Trace;FPGA},
  doi={10.1109/LASCAS51355.2021.9459137}}

@INPROCEEDINGS{Sohal20,
  author={Sohal, Parul and Tabish, Rohan and Drepper, Ulrich and Mancuso, Renato},
  booktitle={2020 IEEE Real-Time Systems Symposium (RTSS)}, 
  title={E-WarP: A System-wide Framework for Memory Bandwidth Profiling and Management}, 
  year={2020},
  volume={},
  number={},
  pages={345-357},
  keywords={Runtime;Embedded systems;Roads;Memory management;Predictive models;Real-time systems;Performance analysis;profiling;DRAM saturation;memory partitioning;ARM QoS;memory regulation;bandwidth management;WCET prediction;temporal isolation;accelerator bandwidth management;cumulative memory transaction;traffic shaping;budget based regulation},
  doi={10.1109/RTSS49844.2020.00039}}

@INPROCEEDINGS{Izhbirdeev2024,
  author={Izhbirdeev, Ivan and Hoornaert, Denis and Chen, Weifan and Zuepke, Alexander and Hammad, Youssef and Caccamo, Marco and Mancuso, Renato},
  booktitle={2024 IEEE Real-Time Systems Symposium (RTSS)}, 
  title={Coherence-Aided Memory Bandwidth Regulation}, 
  year={2024},
  volume={},
  number={},
  pages={322-335},
  keywords={Regulators;Process control;Bandwidth;Coherence;Regulation;Real-time systems;Software;Spatiotemporal phenomena;Resource management;Monitoring;bandwidth regulation;coherence;cache},
  doi={10.1109/RTSS62706.2024.00035}}

@InProceedings{chenTPA,
  author =	{Chen, Weifan and Izhbirdeev, Ivan and Hoornaert, Denis and Roozkhosh, Shahin and Carpanedo, Patrick and Sharma, Sanskriti and Mancuso, Renato},
  title =	{{Low-Overhead Online Assessment of Timely Progress as a System Commodity}},
  booktitle =	{35th Euromicro Conference on Real-Time Systems (ECRTS 2023)},
  pages =	{13:1--13:26},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-280-8},
  ISSN =	{1868-8969},
  year =	{2023},
  volume =	{262},
  editor =	{Papadopoulos, Alessandro V.},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ECRTS.2023.13},
  URN =		{urn:nbn:de:0030-drops-180428},
  doi =		{10.4230/LIPIcs.ECRTS.2023.13},
  annote =	{Keywords: progress-aware regulation, hardware assisted runtime monitoring, timing annotation, control flow graph}
}


@inproceedings{Valgrind,
author = {Nethercote, Nicholas and Seward, Julian},
title = {Valgrind: a framework for heavyweight dynamic binary instrumentation},
year = {2007},
isbn = {9781595936332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1250734.1250746},
doi = {10.1145/1250734.1250746},
abstract = {Dynamic binary instrumentation (DBI) frameworks make it easy to build dynamic binary analysis (DBA) tools such as checkers and profilers. Much of the focus on DBI frameworks has been on performance; little attention has been paid to their capabilities. As a result, we believe the potential of DBI has not been fully exploited.In this paper we describe Valgrind, a DBI framework designed for building heavyweight DBA tools. We focus on its unique support for shadow values-a powerful but previously little-studied and difficult-to-implement DBA technique, which requires a tool to shadow every register and memory value with another value that describes it. This support accounts for several crucial design features that distinguish Valgrind from other DBI frameworks. Because of these features, lightweight tools built with Valgrind run comparatively slowly, but Valgrind can be used to build more interesting, heavyweight tools that are difficult or impossible to build with other DBI frameworks such as Pin and DynamoRIO.},
booktitle = {Proceedings of the 28th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {89–100},
numpages = {12},
keywords = {shadow values, dynamic binary instrumentation, dynamic binary analysis, Valgrind, Memcheck},
location = {San Diego, California, USA},
series = {PLDI '07}
}


@inproceedings{LUK-PIN,
author = {Luk, Chi-Keung and Cohn, Robert and Muth, Robert and Patil, Harish and Klauser, Artur and Lowney, Geoff and Wallace, Steven and Reddi, Vijay Janapa and Hazelwood, Kim},
title = {Pin: building customized program analysis tools with dynamic instrumentation},
year = {2005},
isbn = {1595930566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1065010.1065034},
doi = {10.1145/1065010.1065034},
abstract = {Robust and powerful software instrumentation tools are essential for program analysis tasks such as profiling, performance evaluation, and bug detection. To meet this need, we have developed a new instrumentation system called Pin. Our goals are to provide easy-to-use, portable, transparent, and efficient instrumentation. Instrumentation tools (called Pintools) are written in C/C++ using Pin's rich API. Pin follows the model of ATOM, allowing the tool writer to analyze an application at the instruction level without the need for detailed knowledge of the underlying instruction set. The API is designed to be architecture independent whenever possible, making Pintools source compatible across different architectures. However, a Pintool can access architecture-specific details when necessary. Instrumentation with Pin is mostly transparent as the application and Pintool observe the application's original, uninstrumented behavior. Pin uses dynamic compilation to instrument executables while they are running. For efficiency, Pin uses several techniques, including inlining, register re-allocation, liveness analysis, and instruction scheduling to optimize instrumentation. This fully automated approach delivers significantly better instrumentation performance than similar tools. For example, Pin is 3.3x faster than Valgrind and 2x faster than DynamoRIO for basic-block counting. To illustrate Pin's versatility, we describe two Pintools in daily use to analyze production software. Pin is publicly available for Linux platforms on four architectures: IA32 (32-bit x86), EM64T (64-bit x86), Itanium®, and ARM. In the ten months since Pin 2 was released in July 2004, there have been over 3000 downloads from its website.},
booktitle = {Proceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {190–200},
numpages = {11},
keywords = {dynamic compilation, instrumentation, program analysis tools},
location = {Chicago, IL, USA},
series = {PLDI '05}
}


@INPROCEEDINGS{MemProfSurvey,
  author={Ashraf, Imran and Taouil, Mottaqiallah and Bertels, Koen},
  booktitle={2015 10th International Design & Test Symposium (IDT)}, 
  title={Memory profiling for intra-application data-communication quantification: A survey}, 
  year={2015},
  volume={},
  number={},
  pages={32-37},
  keywords={Chlorine;Linux;Radiation detectors;Computer architecture;Instruments;Optimization;Hardware},
  doi={10.1109/IDT.2015.7396732}}

@InProceedings{bellecAttackDetection,
  author =	{Bellec, Nicolas and Rokicki, Simon and Puaut, Isabelle},
  title =	{{Attack Detection Through Monitoring of Timing Deviations in Embedded Real-Time Systems}},
  booktitle =	{32nd Euromicro Conference on Real-Time Systems (ECRTS 2020)},
  pages =	{8:1--8:22},
  series = {Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-152-8},
  ISSN =	{1868-8969},
  year =	{2020},
  volume =	{165},
  editor =	{V\"{o}lp, Marcus},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ECRTS.2020.8},
  URN =		{urn:nbn:de:0030-drops-123719},
  doi =		{10.4230/LIPIcs.ECRTS.2020.8},
  annote =	{Keywords: Real-time systems, security, attack detection, control flow hijacking, WCET estimation, hardware monitoring}
}

@misc{ARMv6M_Architecture_Reference_Manual, 
URL = {https://developer.arm.com/documentation/ddi0419/c/Application-Level-Architecture/ARM-Architecture-Memory-Model/Alignment-support}, 
journal={ARMv6-M Architecture Reference Manual}
} 

@INPROCEEDINGS{Isolbench,
  author={Valsan, Prathap Kumar and Yun, Heechul and Farshchi, Farzad},
  booktitle={2016 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS)}, 
  title={Taming Non-Blocking Caches to Improve Isolation in Multicore Real-Time Systems}, 
  year={2016},
  volume={},
  number={},
  pages={1-12},
  keywords={Multicore processing;Hardware;Benchmark testing;Program processors;Parallel processing;Real-time systems},
  doi={10.1109/RTAS.2016.7461361}}
